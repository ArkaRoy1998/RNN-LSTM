import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, LSTM, TimeDistributed, Concatenate, Dropout
from tensorflow.keras.applications import InceptionResNetV2
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from scipy.spatial.transform import Rotation as R
import cv2

# Mount Google Drive to access files
from google.colab import drive
drive.mount('/content/drive')

# Define paths to your data files
base_path = '/content/drive/MyDrive/'  # Update this to your drive path
image_data_file = os.path.join(base_path, 'data.npy')
angular_momentum_file = os.path.join(base_path, 'data_pi.npy')
rotation_matrix_file = os.path.join(base_path, 'data_R.npy')

# Load data
image_data = np.fromfile(image_data_file, dtype=np.float64) # Shape: (1505280016,)
angular_momentum_data = np.fromfile(angular_momentum_file, dtype=np.float64)  # Shape: (30016,)
rotation_matrix_data = np.fromfile(rotation_matrix_file, dtype=np.float64)   # Shape: (90016,)

# Verify initial shape and size
print(f"Initial shape of image_data: {image_data.shape}")
print(f"Initial size of image_data: {image_data.size}")

print(f"Initial shape of angular_momentum_data: {angular_momentum_data.shape}")
print(f"Initial size of angular_momentum_data: {angular_momentum_data.size}")

print(f"Initial shape of rotation_matrix_data: {rotation_matrix_data.shape}")
print(f"Initial size of rotation_matrix_data: {rotation_matrix_data.size}")

# Remove the first 16 elements from image_data, angular_momentum_data, and rotation_matrix_data
image_data = image_data[16:]
angular_momentum_data = angular_momentum_data[16:]
rotation_matrix_data = rotation_matrix_data[16:]

# Verify the new shape and size after removing elements
print(f"Shape of image_data after removing first 16 elements: {image_data.shape}")
print(f"Size of image_data after removing first 16 elements: {image_data.size}")

print(f"Shape of angular_momentum_data after removing first 16 elements: {angular_momentum_data.shape}")
print(f"Size of angular_momentum_data after removing first 16 elements: {angular_momentum_data.size}")

print(f"Shape of rotation_matrix_data after removing first 16 elements: {rotation_matrix_data.shape}")
print(f"Size of rotation_matrix_data after removing first 16 elements: {rotation_matrix_data.size}")

# Reshape to the expected shapes
num_sequences = 100
num_images = 100
image_data = image_data.reshape(num_sequences, num_images, 224, 224, 3)
angular_momentum_data = angular_momentum_data.reshape(num_sequences, num_images, 3)
rotation_matrix_data = rotation_matrix_data.reshape(num_sequences, num_images, 3, 3)

# Resize images to (180, 320) with padding to maintain aspect ratio
def resize_and_pad(img, target_size):
    h, w, _ = img.shape
    scale = min(target_size[1] / w, target_size[0] / h)
    new_w, new_h = int(w * scale), int(h * scale)
    resized_img = cv2.resize(img, (new_w, new_h))
    top_pad = (target_size[0] - new_h) // 2
    bottom_pad = target_size[0] - new_h - top_pad
    left_pad = (target_size[1] - new_w) // 2
    right_pad = target_size[1] - new_w - left_pad
    padded_img = cv2.copyMakeBorder(resized_img, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=[0, 0, 0])
    return padded_img

target_size = (180, 320)
resized_image_data = np.zeros((num_sequences, num_images, target_size[0], target_size[1], 3), dtype=np.float32)
for i in range(num_sequences):
    for j in range(num_images):
        resized_image_data[i, j] = resize_and_pad(image_data[i, j], target_size)

# Verify the new shape and size after reshaping
print(f"Shape of resized_image_data after reshaping: {resized_image_data.shape}")
print(f"Size of resized_image_data after reshaping: {resized_image_data.size}")

# Check the structure of the resized image data
print(f"Shape of resized_image_data: {resized_image_data.shape}")
print(f"Data type of resized_image_data: {resized_image_data.dtype}")

# Normalize the image data
resized_image_data = resized_image_data.astype('float32') / 255.0

# Normalize the angular momentum and rotation matrix data
scaler_am = StandardScaler()
angular_momentum_data = scaler_am.fit_transform(angular_momentum_data.reshape(-1, angular_momentum_data.shape[-1])).reshape(angular_momentum_data.shape)

scaler_rm = StandardScaler()
rotation_matrix_data = scaler_rm.fit_transform(rotation_matrix_data.reshape(-1, rotation_matrix_data.shape[-1])).reshape(rotation_matrix_data.shape)

# Calculate angular velocity from rotation matrices
def compute_angular_velocity(rotation_matrices, delta_t=1.0):
    angular_velocities = []
    for seq in rotation_matrices:
        seq_angular_velocity = []
        for i in range(len(seq) - 1):
            r1 = R.from_matrix(seq[i])
            r2 = R.from_matrix(seq[i + 1])
            delta_r = r2 * r1.inv()
            angular_velocity = delta_r.as_rotvec() / delta_t
            seq_angular_velocity.append(angular_velocity)
        seq_angular_velocity.append(seq_angular_velocity[-1])  # repeat last velocity for equal length
        angular_velocities.append(seq_angular_velocity)
    return np.array(angular_velocities)

# Calculate angular velocity
angular_velocity_data = compute_angular_velocity(rotation_matrix_data)

# Reshape the data to have sequences of 10 images each
def reshape_sequences(data, seq_length):
    num_sequences, num_images = data.shape[:2]
    reshaped_data = []
    for seq in range(num_sequences):
        for start in range(0, num_images, seq_length):
            end = start + seq_length
            if end <= num_images:
                reshaped_data.append(data[seq, start:end])
    return np.array(reshaped_data)

# Reshape image, angular momentum, and angular velocity data
seq_length = 10
image_data_reshaped = reshape_sequences(resized_image_data, seq_length)
angular_momentum_data_reshaped = reshape_sequences(angular_momentum_data, seq_length)
angular_velocity_data_reshaped = reshape_sequences(angular_velocity_data, seq_length)

# Extract the 10th angular velocity for each smaller sequence as the target
target_angular_velocity = angular_velocity_data_reshaped[:, -1, :]

# Split data into training and testing sets
train_indices, test_indices = train_test_split(np.arange(image_data_reshaped.shape[0]), test_size=0.2, random_state=42)

train_sequences = image_data_reshaped[train_indices]
test_sequences = image_data_reshaped[test_indices]

train_ic_am = angular_momentum_data_reshaped[train_indices, 0, :]
test_ic_am = angular_momentum_data_reshaped[test_indices, 0, :]

train_av = target_angular_velocity[train_indices]
test_av = target_angular_velocity[test_indices]

# Define the model creation function
def create_model():
    inception_resnet = InceptionResNetV2(include_top=False, weights="imagenet", input_shape=(180, 320, 3))
    for layer in inception_resnet.layers[:-4]:
        layer.trainable = False

    model = Sequential()
    model.add(TimeDistributed(inception_resnet, input_shape=(seq_length, 180, 320, 3)))
    model.add(TimeDistributed(Flatten()))
    model.add(LSTM(256, activation='relu', return_sequences=False))
    model.add(Dropout(0.5))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(3))  # Final layer is of 3 neurons for angular velocity components

    return model

# Custom loss function
class CustomAngularVelocityLoss(tf.keras.losses.Loss):
    def call(self, y_true, y_pred):
        e = y_pred - y_true
        euclidean_distance = tf.sqrt(tf.reduce_sum(tf.square(e), axis=-1))
        integral_loss = tf.reduce_mean(euclidean_distance)
        return integral_loss

# Use a distributed strategy for training
strategy = tf.distribute.MirroredStrategy()

with strategy.scope():
    # Define and compile the model
    model = create_model()
    optimizer = tf.keras.optimizers.Adam()
    model.compile(optimizer=optimizer, loss=CustomAngularVelocityLoss(), metrics=['mae'])

    # Train the model
    model.fit(train_sequences, train_av, validation_split=0.2, batch_size=8, epochs=10)

# Save the model and weights
model_save_path = '/content/trained_model_10epoch.h5'
weights_save_path = '/content/trained_model_10epoch_weights.h5'

model.save(model_save_path)
model.save_weights(weights_save_path)

# Evaluate the model on the testing sequence
test_sequence = test_sequences[0]
test_ic_am = test_ic_am[0]
test_av = test_av[:20]  # Select first 20 for comparison

test_sequence = np.expand_dims(test_sequence, axis=0)
test_ic_am = np.expand_dims(test_ic_am, axis=0)

predicted_test_av = model.predict(test_sequence)

# Display sample predictions
def display_sample_predictions(predicted_av, true_av, num_samples=10, title='Sample Predicted vs Actual Angular Velocities'):
    print(title)
    for i in range(min(num_samples, len(predicted_av))):
        print(f"Sample {i+1} - Predicted: {predicted_av[i]}, Actual: {true_av[i]}")

# Sample size to display
num_samples = 20

# Display sample predictions for testing sequence
print("Testing Sequence - Sample Predictions:")
display_sample_predictions(predicted_test_av, test_av, num_samples, 'Testing Sequence - Sample Predicted vs Actual Angular Velocities')

# Create a dataframe for the sample predictions
df = pd.DataFrame({
    'Predicted_x': predicted_test_av[:, 0],
    'Predicted_y': predicted_test_av[:, 1],
    'Predicted_z': predicted_test_av[:, 2],
    'Actual_x': test_av[:, 0],
    'Actual_y': test_av[:, 1],
    'Actual_z': test_av[:, 2]
})

# Display the dataframe
print(df.head(20))

# Plotting the norm of the difference between predicted and actual angular velocities for the testing sequence
test_diff_norms = np.linalg.norm(predicted_test_av - test_av, axis=1)

plt.figure(figsize=(12, 6))
plt.plot(test_diff_norms, label='Test Difference Norm')
plt.title('Testing Sequence - Norm of Difference Between Predicted vs Actual Angular Velocity')
plt.xlabel('Sample')
plt.ylabel('Difference Norm')
plt.legend()
plt.show()
